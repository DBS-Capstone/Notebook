{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import Library**","metadata":{}},{"cell_type":"code","source":"!pip install -U noisereduce tensorflowjs --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Common\nimport os\nimport gdown\nimport random\nimport librosa\nimport numpy as np\nimport soundfile as sf\nimport tensorflow as tf\nimport noisereduce as nr\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\n\n# Datasets\nfrom datasets import Audio, load_from_disk, Dataset, concatenate_datasets, ClassLabel\nfrom collections import Counter, defaultdict\n\n# Modelling\nimport tensorflowjs as tfjs\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom tensorflow.keras import models, layers, callbacks, optimizers\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Secret\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nBirdSet_RAW_URL = user_secrets.get_secret(\"BirdSet_RAW_URL\")\nBirdSet_10_16Khz_URL = user_secrets.get_secret(\"BirdSet_10_16Khz_URL\")\nBirdSet_10_16Khz_Features_URL = user_secrets.get_secret(\"BirdSet_10_16Khz_Features_URL\")\nBirdSet_10_16Khz_Balanced_URL = user_secrets.get_secret(\"BirdSet_10_16Khz_Balanced_URL\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Load Dataset**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_RAW_URL, output=\"../temp/BirdSet_RAW\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_from_disk(\"../temp/BirdSet_RAW\")\ndataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = dataset[\"train\"]\ntrain_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"ebird_code_names = train_ds.features[\"ebird_code\"].names\nebird_code_names","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counter = Counter()\n\n# Hitung berdasarkan ebird_code sebagai key\ndef count_label_ids(example):\n    label_id = example[\"ebird_code\"]\n    label_counter.update([label_id])\n\ntrain_ds.map(count_label_ids)\n\n# Menampilkan label top 10 kelas\nfor label_id, count in label_counter.most_common(10):\n    label_name = ebird_code_names[label_id]\n    print(f\"{label_name}: {count}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Preprocessing Dataset**","metadata":{}},{"cell_type":"markdown","source":"## **Select Top 10 Labels**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_RAW_URL, output=\"../temp/BirdSet_RAW\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_from_disk(\"../temp/BirdSet_RAW\")\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))\ndataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = dataset[\"train\"]\ntrain_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"top_10_labels = dict(label_counter.most_common(10))\ntrain_ds = train_ds.filter(lambda x: x[\"ebird_code\"] in top_10_labels)\ntrain_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Buat mapping: label lama -> label baru (0-9)\nebird_code_names = train_ds.features[\"ebird_code\"].names\nebird_codes = set(train_ds[\"ebird_code\"])\nlabel2idx = {label: idx for idx, label in enumerate(ebird_codes)}\n\ndef remap_labels(example):\n    example[\"ebird_code\"] = label2idx[example[\"ebird_code\"]]\n    return example\n\n# Terapkan ke seluruh dataset\ntrain_ds = train_ds.map(remap_labels)\n\n# Buat objek ClassLabel baru\nnew_class_label = ClassLabel(num_classes=len(ebird_codes), names=[ebird_code_names[ebird_code] for ebird_code in ebird_codes])\n\n# Cast ulang kolom label agar metadata-nya ikut berubah\ntrain_ds = train_ds.cast_column(\"ebird_code\", new_class_label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds.save_to_disk(\"../temp/BirdSet_10_16Khz\", num_proc=os.cpu_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czvf \"./BirdSet_10_16Khz.tar.gz\" \"../temp/BirdSet_10_16Khz\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Event Based Audio**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_10_16Khz_URL, output=\"../temp/BirdSet_10_16Khz\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = load_from_disk(\"../temp/BirdSet_10_16Khz\")\ntrain_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cut_events(audio_array, sampling_rate, detected_events, min_len, max_len):\n    total_duration = len(audio_array) / sampling_rate\n    segments = []\n    \n    for start, end in detected_events:\n        event_duration = end - start\n\n        if event_duration < min_len:\n            extension = (min_len - event_duration) / 2\n            start = max(0, start - extension)\n            end = min(total_duration, end + extension)\n\n        if end - start > max_len:\n            end = start + max_len\n\n        start_idx = int(start * sampling_rate)\n        end_idx = int(end * sampling_rate)\n        segment = audio_array[start_idx:end_idx]\n        segments.append(segment)\n\n    if segments:\n        return np.concatenate(segments)\n    else:\n        return audio_array  # fallback kalau kosong\n\n\ndef cut_time_range(audio_array, sampling_rate, start, end):\n    start_idx = int(start * sampling_rate)\n    end_idx = int(end * sampling_rate)\n\n    return audio_array[start_idx:end_idx]\n\n\ndef denoise_audio(audio_array, sampling_rate):\n    return nr.reduce_noise(y=audio_array, sr=sampling_rate)\n\n\ndef pad_or_trim(audio_array, sampling_rate, max_len):\n    desired_len = int(max_len * sampling_rate)\n    current_len = len(audio_array)\n\n    if current_len < desired_len:\n        pad_len = desired_len - current_len\n        audio_array = np.pad(audio_array, (0, pad_len))\n    else:\n        audio_array = audio_array[:desired_len]\n\n    return audio_array\n\ndef load_audio_all_events(sample, min_len, max_len):\n    ebird_code = sample[\"ebird_code\"]\n    _, audio_array, sampling_rate = sample[\"audio\"].values()\n\n    # Potong berdasarkan event atau time range\n    if len(sample[\"detected_events\"]) > 0:\n        audio_array = cut_events(audio_array, sampling_rate, sample[\"detected_events\"], min_len, max_len)\n    elif sample[\"start_time\"] is not None and sample[\"end_time\"] is not None:\n        audio_array = cut_time_range(audio_array, sampling_rate, sample[\"start_time\"], sample[\"end_time\"])\n\n    # Denoising + pad/trim\n    audio_array = denoise_audio(audio_array, sampling_rate)\n    audio_array = pad_or_trim(audio_array, sampling_rate, max_len)\n\n    return {\n        \"ebird_code\": ebird_code,\n        \"sampling_rate\": sampling_rate,\n        \"features\": audio_array\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_ds = train_ds.map(\n    lambda x: load_audio_all_events(x, min_len=5, max_len=5),\n    remove_columns=train_ds.column_names,\n    desc=\"Select Audio by Event...\"\n)\nfeature_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_ds.save_to_disk(\"../temp/BirdSet_10_16Khz_Features\", num_proc=os.cpu_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czvf \"./BirdSet_10_16Khz_Features.tar.gz\" \"../temp/BirdSet_10_16Khz_Features\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Augmentation**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_10_16Khz_Features_URL, output=\"../temp/BirdSet_10_16Khz_Features\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_ds = load_from_disk(\"../temp/BirdSet_10_16Khz_Features\")\nfeature_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counter = Counter()\n\n# Hitung berdasarkan ebird_code sebagai key\ndef count_label_ids(example):\n    label_id = example[\"ebird_code\"]\n    label_counter.update([label_id])\n\nfeature_ds.map(count_label_ids)\n\nebird_code_names = feature_ds.features[\"ebird_code\"].names\n\n# Menampilkan label top 10 kelas\nfor label_id, count in label_counter.most_common(10):\n    label_name = ebird_code_names[label_id]\n    print(f\"{label_name} (id: {label_id}): {count}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Fungsi augmentasi berbasis librosa ===\n# Menambahkan noise acak\ndef add_noise(audio_array, noise_factor=0.005):\n    noise = np.random.randn(len(audio_array))\n    return audio_array + noise_factor * noise\n\n# Menggeser amplitudo (volume)\ndef change_volume(audio_array, gain_db_range=(-6, 6)):\n    gain = np.random.uniform(*gain_db_range)\n    factor = 10.0 ** (gain / 20.0)\n    return audio_array * factor\n\n# Mengubah pitch tanpa mengubah panjang\ndef apply_pitch_shift(audio_array, sampling_rate, steps_range=(-2, 2)):\n    n_steps = np.random.uniform(*steps_range)\n    return librosa.effects.pitch_shift(y=np.array(audio_array), sr=sampling_rate, n_steps=n_steps)\n\n# Inversi sinyal (seperti refleksi cermin)\ndef invert_waveform(audio_array):\n    return -audio_array\n\n# Kliping sinyal (membatasi amplitudo)\ndef clip_audio(audio_array, clip_factor=0.8):\n    max_val = np.max(np.abs(audio_array)) * clip_factor\n    return np.clip(audio_array, -max_val, max_val)\n\n# Fungsi augmentasi satu sample\ndef safe_augment_sample(example):\n    _, sampling_rate, features = example.values()\n\n    if random.random() < 0.5:\n        features = add_noise(features)\n\n    if random.random() < 0.5:\n        features = change_volume(features)\n\n    if random.random() < 0.5:\n        features = apply_pitch_shift(features, sampling_rate)\n\n    if random.random() < 0.3:\n        features = invert_waveform(features)\n\n    if random.random() < 0.3:\n        features = clip_audio(features)\n\n    example[\"features\"] = features\n    return example\n\n# Hitung distribusi awal\ndef get_class_counts(ds):\n    return Counter(ds[\"ebird_code\"])\n\n# Mulai proses augmentasi sampai seimbang\ndef balance_dataset(dataset, target_per_class):\n    all_augmented = []\n\n    class_counts = get_class_counts(dataset)\n    label_info = dataset.features[\"ebird_code\"]\n    under_classes = [cls for cls, count in class_counts.items() if count < target_per_class]\n\n    for cls in under_classes:\n        # Ambil semua sampel dari kelas ini\n        samples = dataset.filter(lambda x: x[\"ebird_code\"] == cls)\n        current_count = len(samples)\n        needed = target_per_class - current_count\n\n        augmented_examples = []\n\n        while len(augmented_examples) < needed:\n            sample = samples[random.randint(0, current_count - 1)]\n            augmented = augment_sample(sample)\n\n            augmented_examples.append(augmented)\n\n        # Batasi hanya sampai `needed`\n        augmented_dataset = Dataset.from_list(augmented_examples[:needed])\n        augmented_dataset = augmented_dataset.cast_column(\"ebird_code\", label_info)\n        all_augmented.append(augmented_dataset)\n\n        print(f\"Augmented {cls} from {current_count} â†’ {target_per_class} samples.\")\n\n    # Gabungkan semua augmented dengan original dataset\n    if all_augmented:\n        dataset = concatenate_datasets([dataset] + all_augmented)\n\n    return dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_ds = balance_dataset(feature_ds, target_per_class=500)\nbalanced_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counter = Counter()\n\n# Hitung berdasarkan ebird_code sebagai key\ndef count_label_ids(example):\n    label_id = example[\"ebird_code\"]\n    label_counter.update([label_id])\n\nbalanced_ds.map(count_label_ids)\n\nebird_code_names = balanced_ds.features[\"ebird_code\"].names\n\n# Menampilkan label top 10 kelas\nfor label_id, count in label_counter.most_common(10):\n    label_name = ebird_code_names[label_id]\n    print(f\"{label_name} (id: {label_id}): {count}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_ds.save_to_disk(\"../temp/BirdSet_10_16Khz_Balanced\", num_proc=os.cpu_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czvf \"./BirdSet_10_16Khz_Balanced.tar.gz\" \"../temp/BirdSet_10_16Khz_Balanced\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Extracting Features**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_10_16Khz_Balanced_URL, output=\"../temp/BirdSet_10_16Khz_Balanced\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_ds = load_from_disk(\"../temp/BirdSet_10_16Khz_Balanced\")\nbalanced_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tidak menggunakan hasil augmentasi!!!","metadata":{}},{"cell_type":"code","source":"def to_melspectrogram(sample):\n    ebird_code = sample[\"ebird_code\"]\n    sampling_rate = sample[\"sampling_rate\"]\n    audio_array = np.array(sample[\"features\"])\n\n    mel_spec = librosa.feature.melspectrogram(y=audio_array, sr=sampling_rate, n_mels=40)\n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n    mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min())\n\n    return {\n        \"ebird_code\": ebird_code,\n        \"sampling_rate\": sampling_rate,\n        \"features\": mel_spec_db\n    }\n\ndef to_mfcc(sample):\n    ebird_code = sample[\"ebird_code\"]\n    sampling_rate = sample[\"sampling_rate\"]\n    audio_array = np.array(sample[\"features\"])\n    \n    mfcc = librosa.feature.mfcc(y=audio_array, sr=sampling_rate, n_mfcc=40)\n\n    return {\n        \"ebird_code\": ebird_code,\n        \"sampling_rate\": sampling_rate,\n        \"features\": mfcc\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Mel-Spectrogram Dataset**","metadata":{}},{"cell_type":"code","source":"melspectro_ds = feature_ds.map(\n    to_melspectrogram,\n    remove_columns=feature_ds.column_names,\n    num_proc=os.cpu_count(),\n    desc=\"Extracting Mel-Spectrogram Features...\"\n)\nmelspectro_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"melspectro_ds.save_to_disk(\"../temp/BirdSet_10_16Khz_Spectrogram\", num_proc=os.cpu_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czvf \"./BirdSet_10_16Khz_Spectrogram.tar.gz\" \"../temp/BirdSet_10_16Khz_Spectrogram\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **MFCC Dataset**","metadata":{}},{"cell_type":"code","source":"mfcc_ds = feature_ds.map(\n    to_mfcc,\n    remove_columns=feature_ds.column_names,\n    num_proc=os.cpu_count(),\n    desc=\"Extracting MFCC Features...\"\n)\nmfcc_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mfcc_ds.save_to_disk(\"../temp/BirdSet_10_16Khz_MFCC\", num_proc=os.cpu_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czvf \"./BirdSet_10_16Khz_MFCC.tar.gz\" \"../temp/BirdSet_10_16Khz_MFCC\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Quality Check**","metadata":{}},{"cell_type":"code","source":"ipd.Audio(feature_ds[0][\"features\"], rate=16_000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"audio_data = librosa.feature.inverse.mel_to_audio(\n    np.array(melspectro_ds[0][\"features\"]).squeeze(), sr=16_000\n)\n\nipd.Audio(audio_data, rate=16_000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"audio_data = librosa.feature.inverse.mfcc_to_audio(\n    np.array(mfcc_ds[0][\"features\"]).squeeze(), sr=16_000\n)\n\nipd.Audio(audio_data, rate=16_000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Modelling (MFCC)**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_10_16Khz_Features_URL, output=\"../temp/BirdSet_10_16Khz_Features\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_ds = load_from_disk(\"../temp/BirdSet_10_16Khz_Features\")\nfeature_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Train-Test Split**","metadata":{}},{"cell_type":"code","source":"# Split awal jadi train dan temp (valid + test)\nsplit = mfcc_ds.train_test_split(test_size=0.2, seed=42)\ntemp_split = split[\"test\"].train_test_split(test_size=0.5, seed=42)\n\n# Gabungkan semua\ntrain_ds = split[\"train\"]\nval_ds = temp_split[\"train\"]\ntest_ds = temp_split[\"test\"]\n\n# Konversi ke tensorflow dataset\ntrain_tfds = train_ds.to_tf_dataset(columns=\"features\", label_cols=\"ebird_code\", batch_size=32, shuffle=True)\nval_tfds = val_ds.to_tf_dataset(columns=\"features\", label_cols=\"ebird_code\", batch_size=128)\ntest_tfds  = test_ds.to_tf_dataset(columns=\"features\", label_cols=\"ebird_code\", batch_size=128)\n\ntrain_tfds = train_tfds.map(lambda x, y: (tf.expand_dims(x, -1), y)).cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)\nval_tfds   = val_tfds.map(lambda x, y: (tf.expand_dims(x, -1), y)).cache().prefetch(tf.data.AUTOTUNE)\ntest_tfds  = test_tfds.map(lambda x, y: (tf.expand_dims(x, -1), y)).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Architecture**","metadata":{}},{"cell_type":"code","source":"lr_schedule = optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=1000,\n    decay_rate=0.9)\noptimizer = optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-5)\ndef create_cnn_model(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Input(shape=input_shape),\n\n        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n\n        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Dropout(0.5),\n        layers.GlobalAveragePooling2D(),\n        \n        layers.Dense(64, activation=\"relu\"),\n        layers.Dropout(0.25),\n        layers.Dense(32, activation=\"relu\"),\n        layers.Dropout(0.3),\n        \n        layers.Dense(num_classes, activation=\"softmax\")\n    ])\n\n    model.compile(\n        optimizer=optimizer,\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"for batch in train_tfds.take(1):\n    print(batch[0].shape, batch[1].shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [example[\"ebird_code\"] for example in mfcc_ds]\nclasses = np.unique(labels)\n\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\", \n    classes=classes, \n    y=labels\n)\nclass_weights = dict(enumerate(class_weights))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = (40, 157, 1)\nnum_classes = len(classes)\n\nearly_stop = callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    restore_best_weights=True,\n    verbose=True\n)\n\nmfcc_model = create_cnn_model(input_shape, num_classes)\n\nhistory = mfcc_model.fit(\n    train_tfds,\n    validation_data=val_tfds,\n    class_weight=class_weights,\n    callbacks=[early_stop],\n    epochs=200,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prediksi label test set\ny_true = []\ny_pred = []\n\nfor batch in test_tfds:\n    X_batch, y_batch = batch\n    preds = mfcc_model.predict(X_batch)\n    pred_labels = np.argmax(preds, axis=1)\n    y_true.extend(y_batch.numpy())\n    y_pred.extend(pred_labels)\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Buat confusion matrix\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues)\n\nplt.title(\"Confusion Matrix Test Set\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Modeling (Mel-Spectrogram)**","metadata":{}},{"cell_type":"code","source":"gdown.download_folder(BirdSet_10_16Khz_Features_URL, output=\"../temp/BirdSet_10_16Khz_Features\", quiet=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_ds = load_from_disk(\"../temp/BirdSet_10_16Khz_Features\")\nfeature_ds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Train-Test Split**","metadata":{}},{"cell_type":"code","source":"# Split awal jadi train dan temp (valid + test)\nsplit = melspectro_ds.train_test_split(test_size=0.2, seed=42)\ntemp_split = split[\"test\"].train_test_split(test_size=0.5, seed=42)\n\n# Gabungkan semua\ntrain_ds = split[\"train\"]\nval_ds = temp_split[\"train\"]\ntest_ds = temp_split[\"test\"]\n\n# Konversi ke tensorflow dataset\ntrain_tfds = train_ds.to_tf_dataset(columns=\"features\", label_cols=\"ebird_code\", batch_size=32, shuffle=True)\nval_tfds = val_ds.to_tf_dataset(columns=\"features\", label_cols=\"ebird_code\", batch_size=128)\ntest_tfds  = test_ds.to_tf_dataset(columns=\"features\", label_cols=\"ebird_code\", batch_size=128)\n\ntrain_tfds = train_tfds.map(lambda x, y: (tf.expand_dims(x, -1), y)).cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)\nval_tfds   = val_tfds.map(lambda x, y: (tf.expand_dims(x, -1), y)).cache().prefetch(tf.data.AUTOTUNE)\ntest_tfds  = test_tfds.map(lambda x, y: (tf.expand_dims(x, -1), y)).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Architecture**","metadata":{}},{"cell_type":"code","source":"lr_schedule = optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=1000,\n    decay_rate=0.9)\noptimizer = optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-5)\n\ndef create_cnn_model(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Input(shape=input_shape),\n\n        layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n\n        layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        \n        layers.Dropout(0.5),\n        layers.Flatten(),\n        \n        layers.Dense(128, activation=\"relu\"),\n        layers.Dropout(0.25),\n        layers.Dense(32, activation=\"relu\"),\n        layers.Dropout(0.3),\n        \n        layers.Dense(num_classes, activation=\"softmax\")\n    ])\n\n    model.compile(\n        optimizer=optimizer,\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"for batch in train_tfds.take(1):\n    print(batch[0].shape, batch[1].shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = [example[\"ebird_code\"] for example in melspectro_ds]\nclasses = np.unique(labels)\n\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\", \n    classes=classes, \n    y=labels\n)\nclass_weights = dict(enumerate(class_weights))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    restore_best_weights=True,\n    verbose=True\n)\n\ninput_shape = (40, 157, 1)\nnum_classes = len(classes)\n\nmelspectro_model = create_cnn_model(input_shape, num_classes)\nhistory = melspectro_model.fit(\n    train_tfds,\n    validation_data=val_tfds,\n    class_weight=class_weights,\n    callbacks=[early_stop],\n    epochs=200,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prediksi label test set\ny_true = []\ny_pred = []\n\nfor batch in test_tfds:\n    X_batch, y_batch = batch\n    preds = melspectro_model.predict(X_batch)\n    pred_labels = np.argmax(preds, axis=1)\n    y_true.extend(y_batch.numpy())\n    y_pred.extend(pred_labels)\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Buat confusion matrix\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues)\n\nplt.title(\"Confusion Matrix Test Set\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Uji Prediksi**","metadata":{}},{"cell_type":"markdown","source":"# **Export Model**","metadata":{}},{"cell_type":"code","source":"# <model>.export(\"SavedModel\")\n# !tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model SavedModel TFJS\n# !tar -czvf \"TFJS.tar.gz\" \"TFJS\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}